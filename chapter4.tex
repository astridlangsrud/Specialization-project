%===================================== CHAP 4 =================================

\chapter{Method and calculations}

Now we move to the modeling of neurons and synapses. In section \ref{set_up} the different elements included in the model are introduced and the most important equations from GLM and MCMC are defined for this system. Simulated experiments with two neurons and one directed synaptic connection was performed for test purposes. Various approaches for inferring time varying weighs were tried and their limitations were investigated. In section \ref{Method} the methods of the test experiments are described in detail. Section \ref{Precalc} presents some calculations based on probability theory to say something about how well the method is expected to perform.

\section{Model}
\label{set_up}

\subsection{Framework}
For the later calculations it is practical to represent the spike data in another format. Define

\begin{equation}
    t \in \{t_1, t_2, ..., t_n\} 
\end{equation}

 where $\{t_1, t_2, ..., t_n\}$ is \ a sequence of equally spaced time steps in [0,T], where $t_{k}-t_{k-1} = t_1$. Also let $s_{i,t} \in \{0,1\}$ be a variable taking value 1 if neuron $i$ spikes in the time bin $(t_{k-1}, t_{k})$, and 0 otherwise. To keep as much information as possible, it is preferable to set the time intervals so small that there is very low probability that the neuron will spike more than once in the intervals. Then, at time $t$ we have a collection of $N$ sequences

\begin{equation}
    S_{t} = \{\{s_{i,t_1}, ,...,s_{i,t-1},s_{it}\}\}_{i=0}^{N} \quad s_{i,t_k} \in {0,1}
\end{equation}

This is illustrated in figure \ref{fig:spike_train}, where the top array is a spike train, and the bottom array is the corresponding binary values for the time bins.

\begin{figure}[h]
\caption{Spike train and corresponding binary numbering of the time bins.}
\label{fig:spike_train}
    \centering
    \includegraphics[scale=0.7]{Sp_t.png}
\end{figure} 

The neurons are assumed to be connected in a network. These connections can be represented by a $N \times N$ matrix, $W$, where each element $w_{ij}=w_{ij}$ is a weight corresponding to the strength of the connection between neuron $i$ and neuron $j$. A positive value for $w_{ij}$ corresponds to an excitatory synaptic connection, whereas a negative weight represents an inhibitory. A weight with value zero, means that there is no connection. 
Typically these weights are considered as fixed. However, as the aim is here to study the synaptic plasticity, the weights are let to vary with time. Thus, there is a weight matrix for every time point, $\{W_t\}_{t=0}^{T}$. For a network consisting of three neurons, the weight matrix at time $t$ will look like

\begin{equation*}
W_t = 
\begin{pmatrix}
w_{11,t} & w_{12,t} & w_{13,t}\\
w_{21,t} & w_{22,t} & w_{23,t}\\
w_{31,t} & w_{32,t} & w_{33,t}\\
\end{pmatrix} 
\end{equation*}
\\

\subsection{GLM and MCMC for this case...}
This section will give an outline of how the Bernoulli GLM and MCMC sampling can be used to make inference on the synaptic weights of neurons in a network. The variable $s_i(t)$ for a neuron $i$ at time $t$, as defined in section ??, can be considered as a stochastic variable from a Bernoulli process. The probability parameter, $\pi_{it}$, represents the probability that neuron $i$ will fire an action potential in time bin $(t,t+1)$. The linear predictor, $\eta_{it}$ consists of the spike history of the neurons, scaled by the synaptic weights from them to neuron $i$, in addition to a background firing rat for neuron $i$. As for a Bernoulli GLM the parameter and the linear predictor is connected through a logit link. This can be expressed mathematically as

\begin{equation}
\begin{split}
    P(s_{it}|S_{t-1}, W_t) =  Ber(\pi_{it}) = \pi_{it}^{s_it}(1-\pi_{it})^{1-s_{it}}, \\ \pi_{it} = h(\eta_{it})= \frac{exp(\eta_{it})}{1+exp(\eta_{it})},\\
    \eta_{it} = \Big (\sum_{j=0}^{N}\sum_{t'=0}^{t'=t-1} w_{ji,t'}s_{jt'} \Big) + b_i, \\
    P(S_t|W_t) = \prod_{i,t} P(s_{it}|S_{t-1}, W_t).
\end{split}
\end{equation}

This corresponds to the likelihood of the observed spiking, given some weights. The prior will be dependent on the learning rule later, but for this projects it is set to be a restriction on how much a weight is allowed to vary from one time step to another, namely

\begin{equation}
    \Gamma = \sum_{j=0}^{N} \sum_{t=0}^{T-1} (w_{ji,t+1}-w_{ji,t})^2.
\end{equation}

The prior distribution is a Gauss distribution of $\Gamma$ with zero mean and some variance $\sigma$. Hence, we have the following expression for the posterior distribution for the weights

\begin{equation}
\label{Posterior}
        P(\{W_t\}_{t=1}^{T}|S_t) = \frac{P(S_t|W_t)\times P(W_t)}{P(S_t)} = \frac{\Big\{\prod_{i,t} P(s_{it}|S_{t-1}, W_t)\Big\} \times \Big\{\frac{exp(-\Gamma /2\sigma)}{\sqrt{2\pi \sigma}}\Big\}}{P(S_t)}, 
\end{equation}

\begin{equation}
        P(S_t) = \int \Big\{\prod_{i,t} P(s_{it}|S_{t-1}, W_t)\Big\} \times \Big\{\frac{exp(-\Gamma /2\sigma)}{\sqrt{2\pi \sigma}}\Big\} d{W_t}.
\end{equation}

Inference will be made by the use of MCMC, so the interesting value to compute is the fraction of the posterior distribution given some suggested new value for the weights, $W_{t, new}$ and that of the previously accepted value $W_t$. Hence, the denominator $P(S_t)$ will disappear, and there is no need to compute it. The product of factors less then one will decrease towards zero as the number of factors increases. Therefore, to avoid computer rounding to zero of the likelihood for a large number of time steps, it is necessary to use the log values instead. The value we are computing is hence the log of equation ??  inserting the posterior distribution in equation \ref{Posterior}. The expression is the following

\begin{equation}
\label{eq:ratio}
\begin{split}
    \log (\alpha) = 
    \log \frac{\big \{ \prod_{i,t} P(s_{it}|S_{t-1}, W_{t,new})\big \} \times exp(-\Gamma_{new} /2\sigma)}{\big \{ \prod_{i,t}  P(s_{it}|S_{t-1}, W_t) \big \} \times exp(-\Gamma /2\sigma)} \\
    = \Big \{ \sum_{i,t} \log( P(s_{it}|S_{t-1}, W_{t,new})) - \log( P(s_{it}|S_{t-1}, W_t)) \Big \} -\Gamma_{new} /2\sigma +  \Gamma /2\sigma
\end{split}
\end{equation}


\section{Method for test cases}
\label{Method}

In this project three test cases was performed on a simple system consisting of two neurons, 1 and 2, and a synaptic weight, $w_{12}$ directed from neuron 1 to neuron 2.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.6]{Two_neurons_illustration.png}
\end{figure}

Neuron 1 has a constant probability for spiking, according to a background parameter $b_1$. Neuron 2 has spiking probability that depends on the spiking of $N_1$ in the previous time step through the linear predictor $b_2 + w_{21,t} \cdot s_{1,t-1}$. The actual spiking rate is related to the linear predictor through a logit link, as described in section \ref{sec:Bernoulli}. The distributions of the stochastic variables $s_{i,t}$, representing the spiking in this system, are given by equation \ref{Eq:TestCase}.

\begin{equation}
\begin{split}
\label{Eq:TestCase}
    s_{1t} \sim \text{Ber}(\pi_{1t}) \hspace{3cm} \pi_{1t}= \frac{1}{1+e^{-b_1}} \\
    s_{2t} \sim \text{Ber}(\pi_{2t}) \hspace{1cm} \pi_{2t}= \frac{1}{1+e^{-(b_2 + w_{21,t} \cdot s_{1,t-1})}}
\end{split}
\end{equation}

Typical parameter values to be used in the test cases are 0.5 and 1 for b1, and -1 and 0 for b2. The value for the weight $w_{12}$ will be let to vary with time, but a typical size for it will be $w_{12}=0.7$. To get a better intuition it is useful to translate this to the corresponding firing rates. Table \ref{table:parameters} shows the resulting firing rates for the different parameter values


\begin{table}[!h]
\centering
\begin{tabular}{|c|c|c|c|}
	\hline
	Neuron & b & \pi_{s_{1,t-1}=0} & \pi_{s_{1,t-1}=1} \\
	\hline\hline
	1 & 0 & 0.5 & 0.5\\
	\hline
	1 & 0.5 & 0.62 & 0.62\\
	\hline
	2 & -1  & 0.27 & 0.43\\
	\hline
	2 & 0  & 0.5 & 0.77\\
	\hline
\end{tabular}
\caption{Background parameter and corresponding spiking rates for neuron 1 and neuron 2}
\label{table:parameters}
\end{table}

The purpose of all the test cases was to infer the underlying weights given the spike train data. Normalizes root mean square error (rnMSE) was used measure the goodness of the various test cases. This was calculated according to the following equation,

\begin{equation}
    rnMSE = \sqrt{\frac{\sum_t(w_{12,t}'-w_{12,t})^2}{\sum_t w_{12,t}^2}},
\end{equation}

where $w_{12,t}'$  are the inferred weights and $w_{12,t}$ are the generative weights.

\subsection{CASE 1: Inferring constant weight with Newton method}

The series of Bernoulli variables $\{s_{1t}\}_{t=1}^T$ and $\{s_{2t}\}_{t=1}^T$ were drawn according to equations \ref{Eq:TestCase}, with constant weight $w_{21,t} = w_{21} = 0.7$ and $T=1000$. The score and Fisher value for this situation is 

\begin{equation}
\begin{split}
    score(w_{12}) = \sum_{t=2}^{T} s_{1, t-1} (s_{2,t}-\pi_{2,t}), \\
    H(w_{12}) = \sum_{t=2}^T s_{1, t-1}^2 \pi_t(1-\pi_t) = \sum_{t=1}^T s_{1, t-1} \pi_t(1-\pi_t).
\end{split}
\end{equation}

The last equivalence is valid since $s_{1,t}$ only can take values 1 or 0. 

An initial guess was set to $w_{12} = 1$. Newton iterations, as given by equation \ref{eq:Newton}, were performed until convergence.\\ 

\subsection{CASE 2: Inferring dynamic weights with Metropolis-Hastings}
Now the weights were let to vary, and the aim was to infer the vector ${\bf w_{12}}$ of length T, of weights for each time step. In this test case 10 time steps was used, $T=10$. In the first time step, there is no "previous step" that can be used to evaluate the spike rate of neuron 2. Therefore, in this time step the only thing happening is generating the variable $s_{1,t=1}$. This means that there are 9 weights to infer, corresponding to $t=2,...,10$. From $t=2$, spikes for both neurons are generated, where the spike rate for neuron 2 is computed according to value of the linear predictor. 

Before simulation the neuron spiking, the generative weight trajectory was specified. The weight at $t=2$ was set to 0.7, and the remaining weights were drawn as

\begin{equation}
    w_{t} = w_{t-1} + |n(0,0.001)|,
\end{equation}

where $|n(0,0.001)|$ is the absolute value of a normal distributed parameter with zero mean and variance equal to $0.001$. Figure \ref{fig:Generative} shows an example of how a typical generative weight trajectory for this test case looks like. 

\begin{figure}
\caption{Example generative weight trajectory in case 2}
\label{fig:Generative}
    \centering
    \includegraphics[scale=0.8]{fig/UL.png}
\end{figure}


In reality the number of time steps is much larger, and changing much slower. However, this is done as a simple way to investigate whether and how well the algorithm can infer time varying weights. 

Spike trains for the two neurons were again drawn according to equation \ref{Eq:TestCase}, this time using the generated time varying weights. These spike trains were drawn various number of times for the same weight trajectory, for comparing the goodness of the algorithm for different amounts of data. In other words, for one weight trajectory $\{w_{12,t}\}_{t=1}^T$ it was simulated spike trains
$\{\{s_{1,t,i}\}_{t=1}^T\}_{i=1}^I$ and $\{\{s_{2,t,i}\}_{t=1}^T\}_{i=1}^I$ with $I \in \{1,10,100,1000,10000 \}$.

To infer the weights from the data, the Metropolis-Hastings algorithm was used. In the algorithm the equations given by ?? needs to be computed in every iteration. For this two neuron system, these equations are calculated as

\begin{equation}
\begin{split}
    l({\bf w_{12}}) = \sum_i \sum_t s_{2,t,i}(b_2 w_{12,t}*s_{1,t-1,i}) - log(1 + exp(b_2 w_{12,t} * s_{1,t-1,i})) \\
    \Gamma({\bf w_{12}}) = \sum_{t=2}^T (w_{12,t} - w_ {12,t-1})^2\\
    \log ( \alpha) = l({\bf w_{12}}_{new}) - l({\bf w_{12}}) - \Gamma({\bf w_{12}}_{new})/2\sigma + \Gamma({\bf w_{12}})/2\sigma.
\end{split}
\end{equation}

$\sigma$ will be referred to as the \textit{prior variance}. In this case the  prior variance was equal to $0.0001$. The proposal distribution used was a multivariate normal distribution with mean vector equal to the weight trajectory from the last iteration, variances equal to $0.0001$ and zero covariances. 
The Metropolis-Hastings procedure for this case is summarized in algorithm \ref{alg:M-H}.

\begin{algorithm}
\caption{}\label{alg:M-H}
\begin{algorithmic}
\State Create empty list $[]$ for weight sample
\State Set start guess ${\bf w_{12}} = {\bf w_{12}}^{(guess)}$
\For {$iteration=1,2,\ldots$}
\State Draw ${\bf w_{12}}_{new}$ from proposal distribution
\State Compute $log(\alpha)$
\State Compute $\alpha = exp(log(\alpha))$
\If {$\alpha > 1$}
\State ${\bf w_{12}} = {\bf w_{12}}_{new}$
\Else 
\If {random.uniform(0,1) $<\alpha$}
\State ${\bf w_{12}} = {\bf w_{12}}_{new}$
\EndIf
\EndIf
\State Add ${\bf w_{12}}$ to sample list
\EndFor
\end{algorithmic}
\end{algorithm}

Two variants of this procedure was performed. One where the initial guess was equal to the generative weights, and one where the initial guess was a random walk around 1. 

\subsection{CASE 3: Weights generated by learning rule}
In reality it is not possible to perform multiple spiking replicates for the same weight trajectory. If the synaptic connections are changing according to learning rules, as presented in section \ref{sec:LR}, the weight updates are dependent on the spiking as time goes by. Since the spiking is a random process, it cannot be reproduced properly. Therefore, we have to rely on only one spike train per neuron, for one weight trajectory. However, in reality the time series is longer and the weights are changing slower and are strongly correlated in time. 

So in this test case weights and the spikes were generated simultaneously, by means of the STDP learning rule, given by equation \ref{eq:STDP}. The parameter values used for the learning rule were the same as the ones suggested in \cite{Song}, namely $\tau_{\pm} = 20 ms$, $A_+ = 0.005$ and $A_- = 1.05 \times A_+$. The learning rule with these parameters is illustrated in figure \ref{fig:LR}.

\begin{figure}[hbt!]
\caption{STDP learning rule}
\label{fig:LR}
    \centering
    \includegraphics[scale=0.8]{fig/Learning_rule2.png}
\end{figure}

This time $T$ and the spiking rates was set to illustrate realistic time relations. In \cite{Linderman} they use a baseline firing rate with mean 20Hz. To roughly have the same firing level the model was set to have 40 time stamps for representing one second, and the firing rate of the two neurons around one half. 

First the procedure in algorithm \ref{alg:M-H} was performed with 10 seconds (400 time stamps). The weight trajectory drawn for this is plotted in figure \ref{fig:w_STDP}. 


\begin{figure}[hbt!]
\caption{Generative weights drawn according to the STDP rule and the generated spikes}
\label{fig:w_STDP}
    \centering
    \includegraphics[scale=0.8]{fig/LR_underllying.png}
\end{figure}

An easy way to simplify the problem and to utilize the time correlations is to specify equally sized time bins and assume that the weight is constant within each time bin. Since we have restricted the degrees of freedom this can only give a rough estimate of the weights. However, this can still be useful to investigate whether we can characterize the learning trends with only one spike trajectory. The learning rule itself has much fewer parameters than the number of weights. 



\section{Precalculations}
\label{Precalc}

\begin{itemize}
    \item The aim here is to calculate how well I expect my tests to work. Can use hypothesis testing on bernoulli GLM 
    \item Say something about how many time points ect that is needed to be able to detect a change of the weights
\end{itemize}

\begin{wraptable}{r}{4cm}
\begin{center}
 \begin{tabular}{||c c c ||} 
 \hline
 n & Lower & Upper \\ [0.5ex] 
 \hline\hline
 10 & 0.5 & 1 \\ 
 \hline
 100 & 0.7 & 0.84 \\
 \hline
 1000 & 0.748 & 0.792 \\
 \hline
 10000 & 0.7631 & 0.7769 \\ [1ex] 
 \hline
\end{tabular}
\end{center}
\end{wraptable}

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.7]{Conf_intervals.png}
\end{figure}

It is practical to have some understanding of how precisely the weights can be inferred from the spike data. When performing $n$ repeated trials of a Bernoulli process with success rate $\pi$, the sum successes comes from a binomial distribution, with parameters $n$ and $\pi$. For some success count, $n_{success}$, the parameter $\pi$ can be estimated as $\frac{n_{success}}{n}$. How good this estimate is depends on the number of trials, $n$. Figure ?? and table ?? presents the endpoints of range that contains 90\% of the distribution, for different values of n (scaled by one over n). 